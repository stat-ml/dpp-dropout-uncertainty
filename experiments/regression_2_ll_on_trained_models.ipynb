{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "alpaca.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "_7GIIw5AWIPD",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# !python -m pip install git+https://github.com/stat-ml/alpaca"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G5EYn7L7UoUt",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2MDu_gq1U888",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from alpaca.model.ensemble import MLPEnsemble\n",
    "from alpaca.dataloader.builder import build_dataset\n",
    "from alpaca.uncertainty_estimator import build_estimator\n",
    "from alpaca.analysis.metrics import get_uq_metrics"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mshIkNM_U-ul",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "# we have pretrained models scales with these functions\n",
    "def scale(train, val):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train)\n",
    "    train = scaler.transform(train)\n",
    "    val = scaler.transform(val)\n",
    "    return train, val, scaler\n",
    "\n",
    "\n",
    "def split_ood(x_all, y_all, percentile=10):\n",
    "    threshold = np.percentile(y_all, percentile)\n",
    "    ood_idx = np.argwhere(y_all > threshold)[:, 0]\n",
    "    x_ood, y_ood = x_all[ood_idx], y_all[ood_idx]\n",
    "    train_idx = np.argwhere(y_all <= threshold)[:, 0]\n",
    "    x_train, y_train = x_all[train_idx], y_all[train_idx]\n",
    "\n",
    "    return x_train, y_train, x_ood, y_ood\n",
    "\n",
    "\n",
    "def multiple_kfold(k, data_size, max_iterations):\n",
    "    kfold = KFold(k)\n",
    "    for i in range(max_iterations):\n",
    "        if i % k == 0:\n",
    "            data_idx = np.random.permutation(data_size)\n",
    "            idx_generator = kfold.split(data_idx)\n",
    "        train_idx, val_idx = next(idx_generator)\n",
    "        yield data_idx[train_idx], data_idx[val_idx]"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Fp7ERulJU_r6",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# for reproducibility (given same models)\n",
    "SEED = 10\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "im1fDcoYYgVA",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# path = './gdrive/My Drive/chk/expD'\n",
    "path = './data/regression'"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iBATLhpYYypt",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "files = os.listdir(path)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SxGiIhQSe8nU",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.functional import elu\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from alpaca.uncertainty_estimator.masks import build_masks, DEFAULT_MASKS\n",
    "from alpaca.model.ensemble import MLPEnsemble\n",
    "from alpaca.uncertainty_estimator import build_estimator\n",
    "from alpaca.analysis.metrics import get_uq_metrics\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z6gZrxeXe_ZN",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# estimator that invokes low-level alpaca functions\n",
    "def construct_estimator(model, model_type, name, nn_runs):\n",
    "    if model_type == 'mask': \n",
    "        mask = masks[name]\n",
    "        msk = build_estimator(\n",
    "            'mcdue_masked', model, nn_runs=nn_runs,\n",
    "            dropout_mask=mask,\n",
    "            dropout_rate=config['dropout_uq'])\n",
    "        msk.tol_level=1e-10\n",
    "        return msk\n",
    "    elif model_type == 'emask': \n",
    "        mask = emasks[name]\n",
    "        msk = build_estimator(\n",
    "            'emcdue_masked', model, nn_runs=nn_runs,\n",
    "            dropout_mask=mask,\n",
    "            dropout_rate=config['dropout_uq'])\n",
    "        msk.tol_level=1e-10\n",
    "        return msk\n",
    "    else:\n",
    "        return build_estimator(name, model)\n",
    "\n",
    "# evaluator that rescales dataset back and estimates the uncertainty\n",
    "class Evaluator:    \n",
    "    def __init__(self, x_test, y_test, y_scaler, tag='standard'):\n",
    "        self.x_test = torch.DoubleTensor(x_test).cuda()\n",
    "        self.y_test = y_test\n",
    "        self.unscale = lambda y : y_scaler.inverse_transform(y) \n",
    "        self.tag = tag\n",
    "        self.results = []\n",
    "\n",
    "    def bench(self, model, name, model_type='mask', nn_runs): \n",
    "        predictions = model(self.x_test).cpu().detach().numpy()\n",
    "        \n",
    "        errors = np.abs(predictions - self.y_test)\n",
    "        \n",
    "        scaled_errors = self.unscale(predictions) - self.unscale(self.y_test)\n",
    "        rmse = np.sqrt(np.mean(np.square(scaled_errors)))\n",
    "\n",
    "        estimator = construct_estimator(model, model_type, name, nn_runs)\n",
    "        if model_type == 'emask':\n",
    "            name = 'e_' + name\n",
    "        \n",
    "        for run in range(config['n_ue_runs']):\n",
    "            estimations = estimator.estimate(self.x_test)\n",
    "            acc, ndcg, ll = get_uq_metrics(estimations, errors, \n",
    "                                           config['acc_percentile'],\n",
    "                                           bins = [80, 95, 99]\n",
    "                                          )\n",
    "            self.results.append([acc, ndcg, ll, rmse, name, self.tag])\n",
    "            if hasattr(estimator, 'reset'):\n",
    "                estimator.reset()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sJc7ISlJfOAf",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "folder = Path(path)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "usUrrvrH9n_l",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "DEFAULT_MASKS = ['mc_dropout', 'ht_leverages',\n",
    "                  'ht_dpp', 'ht_k_dpp',\n",
    "                  'cov_dpp', 'cov_k_dpp',]"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZUEytwwAfAS1",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "data = []\n",
    "errs = []\n",
    "# loop through files\n",
    "for cnt, file in enumerate(files):\n",
    "  with open(folder / file, 'rb') as f:\n",
    "      dct = pickle.load(f)\n",
    "  print(file)\n",
    "  config = dct['config']\n",
    "  config['n_ue_runs'] = 1\n",
    "  config['acc_percentile'] = .1\n",
    "  state_dict = dct['state_dict']\n",
    "  # loading data\n",
    "  x_train, y_train, x_val, y_val, x_scaler, y_scaler = dct['data']\n",
    "  # loading model\n",
    "  model = MLPEnsemble(\n",
    "      config['layers'], n_models=config['n_ens'],\n",
    "      activation = elu,\n",
    "      reduction='mean')\n",
    "  model.load_state_dict(state_dict)\n",
    "  # preparing the evaluator\n",
    "  standard_evaluator = Evaluator(x_val, y_val, y_scaler, 'standard')\n",
    "  masks = build_masks(DEFAULT_MASKS)\n",
    "  emasks = []\n",
    "  for i in range(config['n_ens']):\n",
    "      msk = build_masks(DEFAULT_MASKS)\n",
    "      emasks.append(msk)\n",
    "  emasks = {key: [e[key] for e in emasks] for key in masks.keys()}\n",
    "  # evaluation\n",
    "  for nn_runs in [10, 30, 100]:\n",
    "    # single model\n",
    "    single_model = model.models[2]\n",
    "    for name in masks: \n",
    "        print(name, end = '|')\n",
    "        try:\n",
    "          standard_evaluator.bench(single_model, name, 'mask', nn_runs)\n",
    "        except Exception as e:\n",
    "          errs.append([e,cnt,file,name])\n",
    "          print('error!', end = '|')\n",
    "    # eue\n",
    "    standard_evaluator.bench(model, 'eue', 'ensemble', nn_runs)    \n",
    "    # masked ensembles\n",
    "    for name in emasks: \n",
    "        print(name, end = '*|')\n",
    "        try:\n",
    "          standard_evaluator.bench(model, name, 'emask', nn_runs)\n",
    "        except Exception as e:\n",
    "          errs.append([e,cnt,file,name])\n",
    "          print('error!', end = '|')\n",
    "    mask_df = pd.DataFrame(standard_evaluator.results, \n",
    "                        columns=['Acc', 'NDCG', 'LL',\n",
    "                                'RMSE', 'Mask', 'Tag'])\n",
    "    mask_df['fname'] = file\n",
    "    mask_df['runs'] = nn_runs\n",
    "    data.append(mask_df)\n",
    "    dfr = pd.concat(data)\n",
    "    dfr.to_csv('fname.csv', index = None)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bmwmHsZkqC_W",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# PLOTTING"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "afmEAUJhyqIb",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "masks_dct = {\n",
    "    'mc_dropout': 'MC dropout',\n",
    "    'e_mc_dropout': 'MC dropout ens.',\n",
    "    \n",
    "    'ht_dpp': 'DPP',\n",
    "    'e_ht_dpp': 'DPP ens.',\n",
    "    \n",
    "    'ht_k_dpp': 'k-DPP',\n",
    "    'e_ht_k_dpp': 'k-DPP ens.',\n",
    "    \n",
    "    'cov_dpp': 'cov DPP',\n",
    "    'e_cov_dpp': 'cov DPP ens.',\n",
    "    \n",
    "    'cov_k_dpp': 'cov k-DPP',\n",
    "    'e_cov_k_dpp': 'cov k-DPP ens.',\n",
    "    \n",
    "    'ht_leverages': 'leverage',\n",
    "    'e_ht_leverages': 'leverage ens.',\n",
    "    \n",
    "    'cov_leverages': 'cov leverage',\n",
    "    'e_cov_leverages': 'cov leverage ens.',\n",
    "    'eue': 'Ensemble'\n",
    "}\n",
    "\n",
    "dset_dct = {\n",
    "    'nava': 'naval propulsion',\n",
    "    'bost': 'boston housing',\n",
    "    'kin8': 'kin8nm',\n",
    "    'ccpp': 'ccpp',\n",
    "    'conc': 'concrete',\n",
    "    'red': 'red wine'\n",
    "}\n",
    "\n",
    "cols_sorted = ['Ensemble',\n",
    "               'MC dropout', \n",
    "               'leverage', \n",
    "               'DPP', \n",
    "               'cov DPP',\n",
    "      ]\n",
    "\n",
    "dset_lims = {\n",
    "    'bost': (-1.2, .5),\n",
    "    'ccpp': (-7.5, .5),\n",
    "    'conc': (-1.5, .3),\n",
    "    'kin8': (-.4, .75),\n",
    "    'nava': (-.5, 1.2),\n",
    "    'red': (-7.5, .0),\n",
    "}"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SfIUGwtdyyHz",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "m2 = [masks_dct[x] if x in masks_dct else x\n",
    "      for x in dfr.Mask.values]\n",
    "dfr['mask'] = m2"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8IR3MLT1y0LR",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "dfr.loc[dfr['mask'] == 'Ensemble', 'runs'] = 100 # some duplication here.."
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7a-axvFWzHOc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "for cq, dset in enumerate(dset_lims.keys()):\n",
    "    plt.subplot(2,3,cq+1)\n",
    "    ax = sns.boxplot(\n",
    "            x = 'mask',\n",
    "            y = 'LL',\n",
    "            hue = 'runs',\n",
    "            width=0.5,\n",
    "            fliersize = 2,\n",
    "            linewidth = .8,\n",
    "            whis = 2.5,\n",
    "            data = dfr[(dfr.dset == dset)],\n",
    "            order = cols_sorted\n",
    "        )\n",
    "    patches = [Rectangle((.5, -200), 1, 300, color = 'r', alpha = .1),\n",
    "               Rectangle((2.5, -200), 1, 300, color = 'b', alpha = .1),\n",
    "              ]\n",
    "    collection = PatchCollection(patches,alpha = .075,color='k')\n",
    "    ax.add_collection(collection)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(linestyle = ':')\n",
    "    plt.title(dset_dct[dset])\n",
    "    plt.xlabel('')\n",
    "    plt.xlim((0, 4.5))\n",
    "    plt.ylim(dset_lims[dset])\n",
    "    if cq != 5:\n",
    "        ax.get_legend().remove()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/ll_uci_supp_D.png', dpi = 600)"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}