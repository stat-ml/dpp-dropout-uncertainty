{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from os import path\n",
    "from argparse import ArgumentParser\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import gpytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import logsumexp\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error as mse\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "from alpaca.utils.ue_metrics import uq_ll\n",
    "from alpaca.ue.masks import BasicBernoulliMask, DPPMask\n",
    "import alpaca.nn as ann\n",
    "from alpaca.utils.model_builder import uncertainty_mode, inference_mode\n",
    "from alpaca.utils.datasets.builder import build_dataset\n",
    "from alpaca.utils.ue_metrics import uq_ll\n",
    "\n",
    "\n",
    "def manual_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "save_dir = Path('data/regression_5')\n",
    "\n",
    "def split_and_scale(x, y):\n",
    "    # Load dat\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "\n",
    "    # Scaler\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    y_scaler = StandardScaler()\n",
    "    y_train = y_scaler.fit_transform(y_train)\n",
    "    y_test = y_scaler.transform(y_test)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test, y_scaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# repeats = 1\n",
    "name = 'boston_housing'\n",
    "\n",
    "manual_seed(42)\n",
    "dataset = build_dataset(name, val_split=0)\n",
    "x, y = dataset.dataset('train')\n",
    "N = x.shape[0] * 0.9  # train size\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# best_tau, best_dropout = 0.01, 0.05\n",
    "# best_tau, best_dropout = select_params(x, y, N, batch_size, name, sampler)\n",
    "\n",
    "# for i in range(repeats):\n",
    "manual_seed(42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def rmse_ll(true_y, prediction, uncertainty, y_scaler):\n",
    "    errors = np.abs(true_y - prediction)\n",
    "    ll = uq_ll(errors, uncertainty) * y_scaler.scale_[0]\n",
    "    rms_error = np.square(\n",
    "        mse(\n",
    "            y_scaler.inverse_transform(true_y),\n",
    "            y_scaler.inverse_transform(prediction)\n",
    "        )\n",
    "    )\n",
    "    return rms_error, ll\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, y_scaler = split_and_scale(x, y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = np.mean(y_train) * np.ones(y_test.shape)\n",
    "uq = np.std(y_train)\n",
    "print(rmse_ll(y_test, pred, uq, y_scaler))\n",
    "\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(ard_num_dims=x_train.shape[1])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train_ = torch.Tensor(x_train).cuda()\n",
    "x_test_ = torch.Tensor(x_test).cuda()\n",
    "y_train_ = torch.Tensor(y_train[:, 0]).cuda()\n",
    "y_test_ = torch.Tensor(y_test[:, 0]).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(x_train_, y_train_, likelihood)\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train().cuda()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 1000\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(x_train_)\n",
    "    # # Calc loss and backprop gradients\n",
    "\n",
    "    loss = -mll(output, y_train_)\n",
    "    loss.backward()\n",
    "    if i % 20 == 0:\n",
    "        print('Iter %d/%d - Loss: %.3f   lengthscale: %s   noise: %.3f' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            model.covar_module.base_kernel.lengthscale.detach().cpu().numpy()[0, :3],\n",
    "            model.likelihood.noise.item()\n",
    "        ))\n",
    "    optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.likelihood.noise.item()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test_x = torch.linspace(0, 1, 51).cuda()\n",
    "x_test_.cuda()\n",
    "model.eval().cuda()\n",
    "likelihood.eval()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    model(x_test_)\n",
    "    observed_pred = likelihood(model(x_test_))\n",
    "    mean = observed_pred.mean\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    uq = np.sqrt((observed_pred._covar.diag()).cpu().numpy())\n",
    "    error, ll = rmse_ll(y_test[:, 0], mean.cpu().numpy(), uq, y_scaler)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(error, ll)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}