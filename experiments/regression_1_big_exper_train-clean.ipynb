{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 1) pick dataset\n",
    "# 2) make n_split_runs=3 runs of 5-kfold\n",
    "# 3) for n_model_runs=3 \n",
    "# 4) train an ensemble of n_ens=5 models\n",
    "# 5) for each single-nn model make n_ue_runs=5 UE runs\n",
    "# 6) for EUE make a UE run\n",
    "# 7) for ensemble-UE make n_ue_runs=5 UE runs\n",
    "# 8) save data for a future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sys.path = [ '/home/etsymbalov/.local/lib/python3.6/site-packages'] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# from experiment_setup import get_model, set_random, build_estimator\n",
    "from alpaca.model.ensemble import MLPEnsemble\n",
    "from alpaca.dataloader.builder import build_dataset\n",
    "from experiments.utils.data import scale, multiple_kfold\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'nn_runs': 100,\n",
    "    'runs': 2,\n",
    "    'max_runs': 20,\n",
    "    # Our train config\n",
    "   'layers': [8, 128, 128, 64, 1],\n",
    "#     'layers': [8, 256, 256, 128, 1],\n",
    "    #'layers': [8, 2048, 2048, 1024, 1],\n",
    "    'epochs': 10_000,\n",
    "    'validation_step': 100,\n",
    "    \n",
    "    # Our train config\n",
    "    'nll_layers': [8, 256, 256, 128, 2],\n",
    "    'nll_epochs': 400,\n",
    "    'nll_validation_step': 50,\n",
    "    \n",
    "    'acc_percentile': 0.1,\n",
    "    'patience': 10,\n",
    "    'dropout_rate': 0.2,\n",
    "    'dropout_uq': 0.5,\n",
    "    'batch_size': 256,\n",
    "    'dataset': 'kin8nm',\n",
    "    'l2_reg': 1e-5,\n",
    "    'ood_percentile': 90,\n",
    "    \n",
    "    'optimizer': {'type': 'Adam', 'lr': 0.01, 'weight_decay':1e-5},\n",
    "    'n_split_runs': 3,\n",
    "    'n_model_runs': 3,\n",
    "    'n_ens': 5,\n",
    "    'n_ue_runs': 5,\n",
    "    'k_folds': 10,\n",
    "    'verbose': False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_opts = ['patience', 'dropout_rate', 'epochs', 'batch_size', 'validation_step', 'verbose']\n",
    "config['train_opts'] = {k: config[k] for k in config if k in train_opts}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    'boston_housing', 'concrete', 'energy_efficiency',\n",
    "    'kin8nm', 'naval_propulsion', 'ccpp', 'red_wine', \n",
    "    'yacht_hydrodynamics'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "boston_housing (506, 13)\n",
      "concrete (1030, 8)\n",
      "energy_efficiency (768, 8)\n",
      "kin8nm (8192, 8)\n",
      "naval_propulsion (11934, 16)\n",
      "ccpp (9568, 4)\n",
      "red_wine (1599, 11)\n",
      "yacht_hydrodynamics (308, 6)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    dataset = build_dataset(dataset_name, val_split=0.0) \n",
    "    x_set, y_set = dataset.dataset('train')\n",
    "    print(dataset_name, x_set.shape)\n",
    "    config['layers'][0] = x_set.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# over datasets\n",
    "for dataset_name in datasets:\n",
    "    dataset = build_dataset(dataset_name, val_split=0.0) \n",
    "    x_set, y_set = dataset.dataset('train')\n",
    "    config['layers'][0] = x_set.shape[-1]\n",
    "    # over different splits\n",
    "    for split_cnt in range(config['n_split_runs']):\n",
    "        kfold_iterator = multiple_kfold(config['k_folds'], \n",
    "                                        len(x_set), \n",
    "                                        config['k_folds'])\n",
    "        # within one split\n",
    "        for kfold_cnt, (val_idx, train_idx) in enumerate(kfold_iterator): \n",
    "            # MIND THE ORDER\n",
    "            x_train, y_train = x_set[train_idx], y_set[train_idx]\n",
    "            x_val, y_val = x_set[val_idx], y_set[val_idx]\n",
    "            x_train, x_val, x_scaler = scale(x_train, x_val)\n",
    "            y_train, y_val, y_scaler = scale(y_train, y_val)\n",
    "            \n",
    "            train_opts = config['train_opts'].copy()\n",
    "            # over model runs\n",
    "            for model_cnt in range(config['n_split_runs']):\n",
    "                model = MLPEnsemble(config['layers'], \n",
    "                                    n_models=config['n_ens'], \n",
    "                                    reduction='mean')\n",
    "                model.fit((x_train, y_train),\n",
    "                          (x_val, y_val),\n",
    "                          **train_opts)\n",
    "                \n",
    "                fname = f'{dataset_name[:4]}_split={split_cnt}_kfold={kfold_cnt}_model={model_cnt}'\n",
    "                dct = {\n",
    "                    'config': config,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'data': (x_train, y_train, x_val, y_val, x_scaler, y_scaler)\n",
    "                }\n",
    "                dir = Path(os.getcwd()) / 'data' / 'regression'\n",
    "                with open(dir / f'{fname}.pickle', 'wb') as f:\n",
    "                    pickle.dump(dct, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}